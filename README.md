# reading_list

> Python is highly required. 

> Pytorch (or Tensorflow) is highly required.

> People who want to do FPGA stuff is not required for python or pytorch.
  

### Week 1:

#### Plan: 

1. Reading codes of [XNOR-Net codes](https://github.com/jiecaoyu/XNOR-Net-PyTorch)
2. Reading paper of [XNOR-Net paper](https://github.com/allenai/XNOR-Net)
3. Understand meaning of xnor operation and concept of quantization networks.

#### Extensive Reading (Compulsory):
1. [Overcoming Challenges in Fixed Point Training of Deep Convolutional Networks](./Krishnamoorthi%20-%202018%20-%20Quantizing%20deep%20convolutional%20networks%20for%20efficient%20inference%20A%20whitepaper.pdf) [Qualcomm Research]
2. [Quantizing deep convolutional networks for efficient inference: A whitepaper](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf) [Google]

#### Submit:
|#|Name|File|
|---|---|----
|:heavy_check_mark:|Weitian|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|
|:heavy_check_mark:|Qian|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|
|:heavy_check_mark:|Yuchen|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|

-------------------

### Week 2:

#### Plan: 

1. Understand codes of XNOR-Net/util.py [codes](https://github.com/jiecaoyu/XNOR-Net-PyTorch/blob/master/CIFAR_10/util.py)
2. Backpropagation of neural network [link](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm)
3. Backpropagation of quantization neural network 
4. Tensorflow version of xnor

#### Extensive Reading (Compulsory):
1.  [Review of quantization networks](https://www.jiqizhixin.com/articles/2018-06-01-11) [Xijiao University]
2.  DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients [Megvii, Face ++]

#### Submit:
|#|Name|File|
|---|---|----
|:heavy_check_mark:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|

-------------------

### Week 3:
1. Another version of [XNOR-Net](https://github.com/XinDongol/reading_list/invitations) (With CUDA code in C++)
2. Backpropagation of quantization neural network 
3. Report learning curve of CIFAR-10 of XNOR-Net

#### Extensive Reading (Compulsory):
1. Finish reading of previous articles.

#### Submit:
|#|Name|File|
|---|---|----
|:clock3:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|



