# reading_list

> Python is highly required. C++ will help you.

> Pytorch (or Tensorflow) is highly required.

> People who want to do FPGA stuff is not required for python or pytorch.

> **Person who misses two reports will leave this group automatically.**:bangbang:

> Please contact with @wetian to join our mail list. 
  

### Week 1:

#### Plan: 

1. Reading codes of [XNOR-Net codes](https://github.com/jiecaoyu/XNOR-Net-PyTorch)
2. Reading paper of [XNOR-Net paper](https://github.com/allenai/XNOR-Net)
3. Understand meaning of xnor operation and concept of quantization networks.

#### Extensive Reading (Compulsory):
1. [Overcoming Challenges in Fixed Point Training of Deep Convolutional Networks](./Krishnamoorthi%20-%202018%20-%20Quantizing%20deep%20convolutional%20networks%20for%20efficient%20inference%20A%20whitepaper.pdf) [Qualcomm Research]
2. [Quantizing deep convolutional networks for efficient inference: A whitepaper](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf) [Google]

#### Submit:
|#|Name|File|
|---|---|----
|:heavy_check_mark:|Weitian|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|
|:heavy_check_mark:|Qian|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|
|:heavy_check_mark:|Yuchen|[example](./Lin%2C%20Talathi%20-%202016%20-%20Overcoming%20Challenges%20in%20Fixed%20Point%20Training%20of%20Deep%20Convolutional%20Networks.pdf)|

-------------------

### Week 2:

#### Plan: 

1. Understand codes of XNOR-Net/util.py [codes](https://github.com/jiecaoyu/XNOR-Net-PyTorch/blob/master/CIFAR_10/util.py)
2. Backpropagation of neural network [link](http://ufldl.stanford.edu/wiki/index.php/Backpropagation_Algorithm)
3. Backpropagation of quantization neural network 
4. Tensorflow version of xnor

#### Extensive Reading (Compulsory):
1.  [Review of quantization networks](https://www.jiqizhixin.com/articles/2018-06-01-11) [Xijiao University]
2.  DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low Bitwidth Gradients [Megvii, Face ++]

#### Submit:
|#|Name|File|
|---|---|----
|:heavy_check_mark:|Weitian|[week2](https://github.com/XinDongol/reading_list/blob/master/Weitian%20Li/Week%202%20Report.pdf)|
|:heavy_check_mark:|Qian|[week1&2](https://github.com/XinDongol/reading_list/blob/master/Qian%20Jiang/week1%20%262.pdf)|
|:heavy_check_mark:|Yuchen|[week2](https://github.com/XinDongol/reading_list/blob/master/Yuchen%20Cai/Report/W2%20Report.pdf)
|:heavy_check_mark:|Kexin|[week2](https://github.com/XinDongol/reading_list/blob/master/Kexin%20Fan/Week%202.pdf)

-------------------

### Week 3:
1. Another version of [XNOR-Net](https://github.com/cooooorn/Pytorch-XNOR-Net) (With CUDA code in C++)
2. Backpropagation of quantization neural network 
3. Report learning curve of CIFAR-10 of XNOR-Net

#### Extensive Reading (Compulsory):
1. Finish reading of previous articles.
2. Deep Learning with Limited Numerical Precision [2015 ICML]


#### Submit:
|#|Name|File|
|---|---|----
|:clock3:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|
|:clock3:|Yudian|




-------------------

### Week 4
1. Summarized optimization problems and methods for quantization neural networks 
2. Read code of [HWGQ](https://github.com/zhaoweicai/hwgq)


#### Extensive Reading (Compulsory):
1. Training Quantized Nets: A Deeper Understanding
2. Deep Learning with Limited Numerical Precision
3. Deep Learning with Low Precision by Half-wave Gaussian Quantization
4. Training and Inference with Integers in Deep Neural Networks


#### Submit:
|#|Name|File|
|---|---|----
|:clock3:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|
|:clock3:|Yudian|

-------------------


### Week 5
1. Reproduce [HWGQ](https://github.com/zhaoweicai/hwgq) with pytorch (If you want to join in one paper now, you should do this.) 
2. Write HWGQ layer in HWGQ with Cuda.

#### Extensive Reading (Compulsory):
1. Training Quantized Nets: A Deeper Understanding
2. Deep Learning with Limited Numerical Precision
3. Deep Learning with Low Precision by Half-wave Gaussian Quantization
4. Training and Inference with Integers in Deep Neural Networks


#### Submit:
|#|Name|File|
|---|---|----
|:clock3:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|
|:clock3:|Yudian|







<!---
### Week n
1. Understand *SignSGD* and *Binaryrelax* 

#### Extensive Reading (Compulsory):
1. signSGD: compressed optimisation for non-convex problems
2. BinaryRelax: A Relaxation Approach For Training Deep Neural Networks With Quantized Weights

#### Submit:
|#|Name|File|
|---|---|----
|:clock3:|Weitian|
|:clock3:|Qian|
|:clock3:|Yuchen|
|:clock3:|Kexin|

-->

